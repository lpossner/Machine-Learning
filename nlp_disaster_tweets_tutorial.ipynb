{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = f\"DunnBC22/distilbert-base-uncased-Tweet_About_Disaster_Or_Not\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 42\n",
    "# samples = 3000\n",
    "\n",
    "# texts = train_df.loc[:samples, \"text\"].to_list()\n",
    "# encoded_input = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "\n",
    "# y_pred = torch.argmax(output.logits, dim=1).detach().numpy()\n",
    "# probs = softmax(output.logits.detach().numpy(), axis=1)\n",
    "# y_test = train_df.loc[:samples, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = precision_score(y_test, y_pred)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# RocCurveDisplay.from_predictions(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = 'hannybal/disaster-twitter-xlm-roberta-al'\n",
    "\n",
    "classifier = pipeline('text-classification', model=MODEL_NAME, tokenizer='cardiffnlp/twitter-xlm-roberta-base')\n",
    "classifier('I can see fire and smoke from the nearby fire!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "\n",
    "texts = train_df.loc[:samples, \"text\"].to_list()\n",
    "\n",
    "classes = classifier(texts)\n",
    "\n",
    "y_pred = [int(dct['label'] == 'LABEL_1') for dct in classes]\n",
    "y_test = train_df.loc[:samples, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
