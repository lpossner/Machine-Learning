{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "class BM25:\n",
    "\n",
    "    def __init__(self, documents, k1=1.5, b=0.75):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.documents = documents\n",
    "        self.N = len(documents)\n",
    "        self.doc_lengths = [len(doc.split()) for doc in documents]\n",
    "        self.avgdl = np.mean(self.doc_lengths)\n",
    "        self.doc_freqs = self._compute_doc_freqs()\n",
    "    \n",
    "    def _compute_doc_freqs(self):\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(self.documents)\n",
    "        self.vocabulary = vectorizer.get_feature_names_out()\n",
    "        doc_freqs = np.array((X > 0).sum(axis=0)).flatten()\n",
    "        return dict(zip(self.vocabulary, doc_freqs))\n",
    "    \n",
    "    def _idf(self, term):\n",
    "        df = self.doc_freqs.get(term, 0)\n",
    "        return np.log((self.N - df + 0.5) / (df + 0.5) + 1.0)\n",
    "    \n",
    "    def _score(self, query, doc_index):\n",
    "        score = 0\n",
    "        doc = self.documents[doc_index].split()\n",
    "        doc_len = self.doc_lengths[doc_index]\n",
    "        \n",
    "        for term in query.split():\n",
    "            if term in self.doc_freqs:\n",
    "                idf = self._idf(term)\n",
    "                tf = doc.count(term)\n",
    "                score += idf * (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * (doc_len / self.avgdl)))\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def search(self, query):\n",
    "        scores = [self._score(query, i) for i in range(self.N)]\n",
    "        return np.argsort(scores)[::-1]  # Sort by descending scores\n",
    "\n",
    "# Load the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "documents = newsgroups.data\n",
    "\n",
    "# Create an instance of BM25\n",
    "bm25 = BM25(documents)\n",
    "\n",
    "# Query example\n",
    "query = \"space exploration\"\n",
    "results = bm25.search(query)\n",
    "\n",
    "# Display results\n",
    "for index in results[:5]:  # Show top 5 results\n",
    "    print(f\"Document: {documents[index][:500]}...\")  # Print the first 500 characters of the document\n",
    "    print(f\"Score: {bm25._score(query, index)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
