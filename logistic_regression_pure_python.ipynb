{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.train_accuracies = []\n",
    "\n",
    "    def fit(self, x, y, epochs):\n",
    "        # x = self._transform_x(x)\n",
    "        # y = self._transform_y(y)\n",
    "\n",
    "        self.weights = np.zeros(x.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(epochs):\n",
    "            x_dot_weights = np.matmul(self.weights, x.transpose()) + self.bias\n",
    "            pred = self._sigmoid(x_dot_weights)\n",
    "            loss = self.compute_loss(y, pred)\n",
    "            print(loss)\n",
    "            error_w, error_b = self.compute_gradients(x, y, pred)\n",
    "            self.update_model_parameters(error_w, error_b)\n",
    "\n",
    "            pred_to_class = [1 if p > 0.5 else 0 for p in pred]\n",
    "            # self.train_accuracies.append(accuracy_score(y, pred_to_class))\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # binary cross entropy\n",
    "        y_zero_loss = y_true * np.log(y_pred + 1e-9)\n",
    "        y_one_loss = (1-y_true) * np.log(1 - y_pred + 1e-9)\n",
    "        return -np.mean(y_zero_loss + y_one_loss)\n",
    "\n",
    "    def compute_gradients(self, x, y_true, y_pred):\n",
    "        # derivative of binary cross entropy\n",
    "        difference =  y_pred - y_true\n",
    "        gradient_b = np.mean(difference)\n",
    "        gradients_w = np.matmul(x.transpose(), difference)\n",
    "        gradients_w = np.array([np.mean(grad) for grad in gradients_w])\n",
    "\n",
    "        return gradients_w, gradient_b\n",
    "\n",
    "    def update_model_parameters(self, error_w, error_b):\n",
    "        self.weights = self.weights - 0.1 * error_w\n",
    "        self.bias = self.bias - 0.1 * error_b\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_dot_weights = np.matmul(x, self.weights.transpose()) + self.bias\n",
    "        probabilities = self._sigmoid(x_dot_weights)\n",
    "        return [1 if p > 0.5 else 0 for p in probabilities]\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return np.array([self._sigmoid_function(value) for value in x])\n",
    "\n",
    "    def _sigmoid_function(self, x):\n",
    "        if x >= 0:\n",
    "            z = np.exp(-x)\n",
    "            return 1 / (1 + z)\n",
    "        else:\n",
    "            z = np.exp(x)\n",
    "            return z / (1 + z)\n",
    "\n",
    "    def _transform_x(self, x):\n",
    "        x = copy.deepcopy(x)\n",
    "        return x.values\n",
    "\n",
    "    def _transform_y(self, y):\n",
    "        y = copy.deepcopy(y)\n",
    "        return y.values.reshape(y.shape[0], 1)\n",
    "    \n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X, y, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class MyLogisticRegression():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, epochs=10000, learning_rate=0.001):\n",
    "        self.weights = np.zeros([X.shape[1]])\n",
    "        self.bias = 0\n",
    "        for _ in range(epochs):\n",
    "            y_predict = self._sigmoid(X)\n",
    "            loss = self.compute_loss(y, y_predict)\n",
    "            # print(loss)\n",
    "            gradient_weights, gradient_bias = self.compute_gradients(X, y, y_predict)\n",
    "            self.weights = self.weights - learning_rate * gradient_weights\n",
    "            self.bias = self.bias - learning_rate * gradient_bias\n",
    "\n",
    "    def compute_loss(self, y_true, y_predict):\n",
    "        y_zero_loss = y_true * np.log(y_predict + 1e-9)\n",
    "        y_one_loss = (1 - y_true) * np.log(1 - y_predict + 1e-9)\n",
    "        return -1 * np.mean(y_zero_loss + y_one_loss)\n",
    "\n",
    "    def compute_gradients(self, X, y_true, y_predict):\n",
    "        difference =  y_predict - y_true\n",
    "        gradient_weights = np.dot(X.transpose(), difference) / y_true.shape[0]\n",
    "        gradient_bias = np.sum(difference) / y_true.shape[0]\n",
    "        return gradient_weights, gradient_bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self._sigmoid(X)\n",
    "        return np.array([1 if p > 0.5 else 0 for p in probabilities])\n",
    "\n",
    "    def _sigmoid(self, X):\n",
    "        return np.array([self._sigmoid_function(X[index, :]) for index in range(X.shape[0])])\n",
    "\n",
    "    def _sigmoid_function(self, x):\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        if z >= 0:\n",
    "            exp = np.exp(-z)\n",
    "            return 1 / (1 + exp)\n",
    "        else:\n",
    "            exp = np.exp(z)\n",
    "            return exp / (1 + exp)\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "my_logistic_regression = MyLogisticRegression()\n",
    "my_logistic_regression.fit(X_train, y_train)\n",
    "y_predict = my_logistic_regression.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(accuracy)\n",
    "\n",
    "logistic_regression = LogisticRegression(solver='newton-cg', max_iter=10000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_predict = logistic_regression.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
