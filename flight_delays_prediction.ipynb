{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute correlations ans variances\n",
    "# correlations = pg.pairwise_corr(flights_df[numerical_columns])\n",
    "# variances = flights_df[numerical_columns].var()\n",
    "\n",
    "# # Select the feature with lower variance in each pair to drop\n",
    "# to_drop = set()\n",
    "# for feature1, feature2 in correlations[['X', 'Y']].values:\n",
    "#     if variances[feature1] < variances[feature2]:\n",
    "#         to_drop.add(feature1)\n",
    "#     else:\n",
    "#         to_drop.add(feature2)\n",
    "\n",
    "# # Drop the low-variance correlated features\n",
    "# flights_df = flights_df.drop(columns=to_drop)\n",
    "\n",
    "# print(f\"Features dropped based on variance: {to_drop}\")\n",
    "\n",
    "# flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "flights_df = pd.read_csv('./data/flight-delays/flights.csv')\n",
    "\n",
    "# Show df\n",
    "flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 20% of values missing\n",
    "flights_df = flights_df.loc[:, (flights_df.isnull().sum() / flights_df.shape[0] < 0.2).values]\n",
    "\n",
    "# Show df\n",
    "flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where ORIGIN_AIRPORT or DESTINATION_AIRPORT contains numbers\n",
    "flights_df = flights_df[~flights_df['ORIGIN_AIRPORT'].str.isnumeric().astype(bool)]\n",
    "flights_df = flights_df[~flights_df['DESTINATION_AIRPORT'].str.isnumeric().astype(bool)]\n",
    "\n",
    "# Columns to convert to categorical\n",
    "categorical_columns = [\n",
    "    'YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK',\n",
    "    'AIRLINE', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
    "    'DIVERTED', 'CANCELLED'\n",
    "]\n",
    "\n",
    "# Convert specified columns to categorical\n",
    "flights_df[categorical_columns] = flights_df[categorical_columns].astype('category')\n",
    "\n",
    "# Convert the rest of the columns to numerical\n",
    "# Identify numerical columns by excluding categorical columns\n",
    "numerical_columns = flights_df.columns.difference(categorical_columns).to_list()\n",
    "\n",
    "# Convert remaining columns to numerical (float for precision)\n",
    "flights_df[numerical_columns] = flights_df[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop cancelled flights\n",
    "flights_df = flights_df[flights_df['CANCELLED'] == 0]\n",
    "flights_df = flights_df.drop(columns=['CANCELLED'])\n",
    "categorical_columns.remove('CANCELLED')\n",
    "\n",
    "# Create target column and drop delayed flights\n",
    "flights_df['DELAYED'] = flights_df['ARRIVAL_DELAY'].apply(lambda arrival_delay: arrival_delay >=15)\n",
    "flights_df = flights_df.drop(columns=['ARRIVAL_DELAY'])\n",
    "numerical_columns.remove('ARRIVAL_DELAY')\n",
    "\n",
    "# Show df\n",
    "flights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing for numerical data\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n",
    "#     # ('scaler', StandardScaler())                    # Standardize numerical features\n",
    "# ])\n",
    "\n",
    "# # Preprocessing for categorical data\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with mode\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))     # One-hot encode categorical features\n",
    "# ])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     [\n",
    "#         ('num', numerical_transformer, numerical_columns),\n",
    "#         ('cat', categorical_transformer, categorical_columns)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Assign sparse array\n",
    "# X = preprocessor.fit_transform(flights_df.drop(columns=['DELAYED']))\n",
    "# y = flights_df['DELAYED'].values\n",
    "\n",
    "# # Create train and test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size = 0.3 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"XGBoost\")\n",
    "\n",
    "# clf = xgb.XGBClassifier()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    "# print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# print(f\"Recall: {recall}\")\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Pandas output\n",
    "set_config(transform_output = \"pandas\")\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n",
    "    # ('scaler', StandardScaler())                   # Standardize numerical features\n",
    "])\n",
    "flights_df[numerical_columns] = numerical_transformer.fit_transform(flights_df[numerical_columns])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),                       # Impute missing values with mode\n",
    "    # ('onehot', OneHotEncoder(handle_unknown='ignore'))     # One-hot encode categorical features\n",
    "])\n",
    "flights_df[categorical_columns] = categorical_transformer.fit_transform(flights_df[categorical_columns])\n",
    "\n",
    "# Convert specified columns to categorical, again\n",
    "flights_df[categorical_columns] = flights_df[categorical_columns].astype('category')\n",
    "\n",
    "# Assign from data frames\n",
    "X = flights_df.drop(columns=['DELAYED'])\n",
    "y = flights_df['DELAYED']\n",
    "\n",
    "# Create train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3 \n",
    ")\n",
    "\n",
    "# Show df\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(enable_categorical=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
