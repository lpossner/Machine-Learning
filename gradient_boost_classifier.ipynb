{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "## Titanic\n",
    "data_titanic = pd.read_csv(\"./data/machine_failure/train.csv\")\n",
    "\n",
    "column_titanic_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_titanic = data_titanic.rename(columns=column_titanic_dict)\n",
    "\n",
    "train_X_titanic_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_titanic_columns = [\"Survived\"]\n",
    "train_X_titanic_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_titanic = data_titanic[train_X_titanic_columns]\n",
    "y_titanic = data_titanic[train_y_titanic_columns]\n",
    " \n",
    "X_titanic.loc[:, train_X_titanic_ordinal_columns] = OrdinalEncoder().fit_transform(X_titanic[train_X_titanic_ordinal_columns])\n",
    "\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X_titanic, y_titanic, test_size=0.4)\n",
    "y_titanic_train = np.squeeze(y_titanic_train)\n",
    "y_titanic_test = np.squeeze(y_titanic_test)\n",
    "\n",
    "## Machine Failure\n",
    "data_machine_failure = pd.read_csv(\"./data/machine_failure/train.csv\")\n",
    "\n",
    "column_machine_failure_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_machine_failure = data_machine_failure.rename(columns=column_machine_failure_dict)\n",
    "\n",
    "train_X_machine_failure_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_machine_failure_columns = [\"Survived\"]\n",
    "train_X_machine_failure_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_machine_failure = data_machine_failure[train_X_machine_failure_columns]\n",
    "y_machine_failure = data_machine_failure[train_y_machine_failure_columns]\n",
    " \n",
    "X_machine_failure.loc[:, train_X_machine_failure_ordinal_columns] = OrdinalEncoder().fit_transform(X_machine_failure[train_X_machine_failure_ordinal_columns])\n",
    "\n",
    "X_machine_failure_train, X_machine_failure_test, y_machine_failure_train, y_machine_failure_test = train_test_split(X_machine_failure, y_machine_failure, test_size=0.4)\n",
    "y_machine_failure_train = np.squeeze(y_machine_failure_train)\n",
    "y_machine_failure_test = np.squeeze(y_machine_failure_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Titanic\n",
    "## Standard Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "X_titanic_train_1, X_titanic_train_2, y_titanic_train_1, y_titanic_train_2 = train_test_split(X_titanic_train, y_titanic_train, test_size=0.5)\n",
    "y_titanic_train_1 = np.squeeze(y_titanic_train_1)\n",
    "y_titanic_train_2 = np.squeeze(y_titanic_train_2)\n",
    "\n",
    "param_grid = [\n",
    "  {\"ada_bst_clf__n_estimators\": [100, 1000, 10000],\n",
    "   \"ada_bst_clf__learning_rate\": [0.01, 0.1, 1]}\n",
    "]\n",
    "gradient_bst_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ada_bst_clf\", GradientBoostingClassifier()),]),\n",
    "    param_grid, cv=10, verbose=3)\n",
    "gradient_bst_clf.fit(X_titanic_train_2, y_titanic_train_2)\n",
    "# Predict\n",
    "y_titanic_pred = gradient_bst_clf.predict(X_titanic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_titanic_test, y_titanic_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_titanic_test, y_titanic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Failure\n",
    "## Standard Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "X_machine_failure_train_1, X_machine_failure_train_2, y_machine_failure_train_1, y_machine_failure_train_2 = train_test_split(X_machine_failure_train, y_machine_failure_train, test_size=0.5)\n",
    "y_machine_failure_train_1 = np.squeeze(y_machine_failure_train_1)\n",
    "y_machine_failure_train_2 = np.squeeze(y_machine_failure_train_2)\n",
    "\n",
    "param_grid = [\n",
    "  {\"ada_bst_clf__n_estimators\": [100, 1000, 10000],\n",
    "   \"ada_bst_clf__learning_rate\": [0.01, 0.1, 1]}\n",
    "]\n",
    "gradient_bst_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ada_bst_clf\", GradientBoostingClassifier()),]),\n",
    "    param_grid, cv=10, verbose=3)\n",
    "gradient_bst_clf.fit(X_machine_failure_train_2, y_machine_failure_train_2)\n",
    "# Predict\n",
    "y_machine_failure_pred = gradient_bst_clf.predict(X_machine_failure_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_machine_failure_test, y_machine_failure_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Titanic\n",
    "## MinMax Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "X_titanic_train_1, X_titanic_train_2, y_titanic_train_1, y_titanic_train_2 = train_test_split(X_titanic_train, y_titanic_train, test_size=0.5)\n",
    "y_titanic_train_1 = np.squeeze(y_titanic_train_1)\n",
    "y_titanic_train_2 = np.squeeze(y_titanic_train_2)\n",
    "\n",
    "param_grid = [\n",
    "  {\"ada_bst_clf__n_estimators\": [100, 1000, 10000],\n",
    "   \"ada_bst_clf__learning_rate\": [0.01, 0.1, 1]}\n",
    "]\n",
    "gradient_bst_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"ada_bst_clf\", GradientBoostingClassifier()),]),\n",
    "    param_grid, cv=10, verbose=3)\n",
    "gradient_bst_clf.fit(X_titanic_train_2, y_titanic_train_2)\n",
    "# Predict\n",
    "y_titanic_pred = gradient_bst_clf.predict(X_titanic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_titanic_test, y_titanic_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_titanic_test, y_titanic_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_titanic_test, y_titanic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Failure\n",
    "## MinMax Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "X_machine_failure_train_1, X_machine_failure_train_2, y_machine_failure_train_1, y_machine_failure_train_2 = train_test_split(X_machine_failure_train, y_machine_failure_train, test_size=0.5)\n",
    "y_machine_failure_train_1 = np.squeeze(y_machine_failure_train_1)\n",
    "y_machine_failure_train_2 = np.squeeze(y_machine_failure_train_2)\n",
    "\n",
    "param_grid = [\n",
    "  {\"ada_bst_clf__n_estimators\": [100, 1000, 10000],\n",
    "   \"ada_bst_clf__learning_rate\": [0.01, 0.1, 1]}\n",
    "]\n",
    "gradient_bst_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"ada_bst_clf\", GradientBoostingClassifier()),]),\n",
    "    param_grid, cv=10, verbose=3)\n",
    "gradient_bst_clf.fit(X_machine_failure_train_2, y_machine_failure_train_2)\n",
    "# Predict\n",
    "y_machine_failure_pred = gradient_bst_clf.predict(X_machine_failure_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_machine_failure_test, y_machine_failure_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_machine_failure_test, y_machine_failure_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
