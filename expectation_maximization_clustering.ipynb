{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dim = 2\n",
    "mix_dim = 3\n",
    "mix_dist = 5\n",
    "N = 1000\n",
    "\n",
    "distance_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lst = []\n",
    "initial_mean_lst = []\n",
    "initial_cov_lst = []\n",
    "for idx in range(mix_dim):\n",
    "    initial_mean = np.random.uniform(-2, 2, size=[2]) + mix_dist * idx * distance_scale\n",
    "    # initial_mean = np.random.uniform(-2, 2, size=[2])\n",
    "    initial_mean_lst.append(initial_mean)\n",
    "    initial_cov = np.random.uniform(-2, 2, size=[2, 2])\n",
    "    initial_cov = initial_cov @ initial_cov.T\n",
    "    initial_cov_lst.append(initial_cov)\n",
    "    X = np.random.multivariate_normal(mean=initial_mean, cov=initial_cov, size=N)\n",
    "    X_lst.append(X)\n",
    "\n",
    "X = np.concatenate(X_lst, axis=0)\n",
    "initial_mean = np.array(initial_mean_lst)\n",
    "initial_cov = np.array(initial_cov_lst)\n",
    "initial_mix = np.array([1 / mix_dim] * mix_dim)\n",
    "\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.random.uniform(-2, 2, size=[mix_dim, dist_dim]) + np.stack([np.arange(mix_dim) * mix_dist] * dist_dim, axis=1)\n",
    "# cov = np.random.uniform(-2, 2, size=[mix_dim, dist_dim, dist_dim])\n",
    "# cov = cov @ np.transpose(cov, axes=[0, 2, 1])\n",
    "\n",
    "k_means = KMeans(n_clusters=mix_dim)\n",
    "k_means.fit(X)\n",
    "\n",
    "mean = k_means.cluster_centers_\n",
    "cov = np.stack([np.cov(X[k_means.labels_ == label].T, ddof=1) for label in np.unique(k_means.labels_)], axis=0)\n",
    "mix = np.random.uniform(0, 1, size=mix_dim)\n",
    "mix = mix / np.sum(mix)\n",
    "\n",
    "mean_mse = []\n",
    "cov_mse = []\n",
    "mix_mse = []\n",
    "mean_mse.append(np.mean((mean - initial_mean) ** 2))\n",
    "cov_mse.append(np.mean((cov - initial_cov) ** 2))\n",
    "mix_mse.append(np.mean((mix - initial_mix) ** 2))\n",
    "\n",
    "for iter in range(1000):\n",
    "    # Expectation Step\n",
    "    prob = np.array(\n",
    "        [\n",
    "            multivariate_normal(\n",
    "                mean=component_mean, cov=component_cov, allow_singular=True\n",
    "            ).pdf(X)\n",
    "            * component_mix\n",
    "            for component_mean, component_cov, component_mix in zip(mean, cov, mix)\n",
    "        ]\n",
    "    )\n",
    "    # Maximization Step\n",
    "    prob = prob / np.sum(prob, axis=0)\n",
    "    mix = np.mean(prob, axis=1)\n",
    "    mean = (\n",
    "        np.sum(prob[:, :, None] * X, axis=1) / np.sum(prob, axis=1)[:, None]\n",
    "    )\n",
    "    cov = (\n",
    "        np.sum(\n",
    "            prob[:, :, None, None]\n",
    "            * np.transpose(\n",
    "                X[:, None, :] - mean[None, :, :], axes=[1, 0, 2]\n",
    "            )[:, :, :, None]\n",
    "            @ np.transpose(\n",
    "                X[:, None, :] - mean[None, :, :], axes=[1, 0, 2]\n",
    "            )[:, :, None, :],\n",
    "            axis=1,\n",
    "        )\n",
    "        / np.sum(prob, axis=1)[:, None, None]\n",
    "    )\n",
    "\n",
    "    mean_mse.append(np.mean((mean - initial_mean) ** 2))\n",
    "    cov_mse.append(np.mean((cov - initial_cov) ** 2))\n",
    "    mix_mse.append(np.mean((mix - initial_mix) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(mean_mse)\n",
    "plt.figure()\n",
    "plt.loglog(cov_mse)\n",
    "plt.figure()\n",
    "plt.loglog(mix_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = np.array(\n",
    "    [\n",
    "        multivariate_normal(\n",
    "            mean=component_mean, cov=component_cov, allow_singular=True\n",
    "        ).pdf(X)\n",
    "        * component_mix\n",
    "        for component_mean, component_cov, component_mix in zip(mean, cov, mix)\n",
    "    ]\n",
    ")\n",
    "pred = np.argmax(pred_prob, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], color=\"k\")\n",
    "\n",
    "for cluster in np.unique(pred):\n",
    "    sns.scatterplot(x=X[pred == cluster, 0], y=X[pred == cluster, 1], marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for mix in range(0, mix_dim):\n",
    "    hits = hits + np.sum(pred[mix * N: (mix+1) * N] == mix)\n",
    "\n",
    "print(f\"Precision: {hits / N / mix_dim * 100}% \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
